### README: Pipeline de AnÃ¡lise e Engenharia de Dados de TelecomunicaÃ§Ãµes

Este projeto demonstra um pipeline completo de **anÃ¡lise e engenharia de dados**, desde o processamento inicial de arquivos brutos atÃ© a visualizaÃ§Ã£o final em um painel de Business Intelligence (BI). O foco Ã© em dados de telecomunicaÃ§Ãµes, mostrando como transformar informaÃ§Ãµes complexas em insights valiosos.

---

### âš™ï¸ Tecnologias Utilizadas

* **Python:** Para a extraÃ§Ã£o e limpeza inicial dos dados.
* **PostgreSQL:** Banco de dados relacional para armazenamento dos dados em camadas.
* **Apache Hop:** Ferramenta de ETL (ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga) para orquestrar o fluxo de dados.
* **Power BI:** Para a criaÃ§Ã£o dos painÃ©is de anÃ¡lise e visualizaÃ§Ã£o.
* **Ambiente Virtual (`venv`):** Para isolar as dependÃªncias do projeto em Python.

---

### ğŸš€ VisÃ£o Geral do Projeto

O projeto segue um fluxo lÃ³gico, dividido em trÃªs fases principais:

#### **1. PreparaÃ§Ã£o dos Dados (Python)**

1.  **Leitura do Excel:** O projeto comeÃ§ou com um arquivo `.xls` contendo trÃªs planilhas. Usei o **Python** com a biblioteca Pandas e a `engine='openpyxl'` para ler cada uma delas.
2.  **PadronizaÃ§Ã£o:** As colunas foram padronizadas para o formato `snake_case`, garantindo consistÃªncia.
3.  **ConversÃ£o para CSV:** Cada planilha foi transformada e salva como um arquivo `.csv` individual, um formato ideal para ingestÃ£o em bases de dados.

#### **2. Pipelines de ETL no Apache Hop**

O banco de dados PostgreSQL foi estruturado com trÃªs schemas (`raw`, `silver`, e `gold`) para organizar o fluxo de dados.

* **IngestÃ£o na camada `raw`:**
    * Pipelines com prefixo `cs*.hpl` carregam os arquivos CSV diretamente nas tabelas da camada `raw`.

* **TransformaÃ§Ã£o para `silver`:**
    * Pipelines com prefixo `transform*.hpl` aplicam as seguintes transformaÃ§Ãµes:
        * ConversÃ£o de tipos (ex: VARCHAR â†’ TIMESTAMP, NUMERIC).
        * GeraÃ§Ã£o de `hash_registro` (baseado em: `data_do_evento`, `latitude`, `longitude`, `tecnologia`, `banda`, `earfcn`, `pci`, `evento`, `cidade`,`RSRP`, `RSRQ`, `SINR`).
        * AdiÃ§Ã£o da coluna `data_ingestao`.


* **Modelagem Dimensional na `gold`:**
    * Tabelas criadas: `dim_cidade`, `dim_operadora`, `dim_frequencia`, `dim_evento`, `dim_tempo`.
    * `fato_medicoes`: Tabela de fatos com chaves estrangeiras para as dimensÃµes.

* **AtualizaÃ§Ã£o ContÃ­nua:**
    * Foi criada uma `VIEW` e uma `MATERIALIZED VIEW` com `REFRESH` agendado para manter os dados sempre atualizados, garantindo a consistÃªncia na anÃ¡lise.

#### **3. AnÃ¡lise e VisualizaÃ§Ã£o (Power BI)**

* **ConexÃ£o direta** com a camada `gold` do PostgreSQL.
* **Dashboards criados:**
    * ğŸ“Š **AnÃ¡lise Geral:** VisÃ£o consolidada de mediÃ§Ãµes por localidade e operadora.
    * ğŸ“¶ **AnÃ¡lise por Qualidade de Sinal:** Performance da rede com base em `RSRP`, `RSRQ` e `SINR`.

---

### ğŸ“ Estrutura de Pastas
â”œâ”€â”€ HOP/
â”‚   â”œâ”€â”€ Cs_.hpl             â†’ Pipelines de ingestÃ£o (CSV â†’ raw)
â”‚   â””â”€â”€ transform_.hpl      â†’ Pipelines de transformaÃ§Ã£o (raw â†’ silver â†’ gold)
â”‚
â”œâ”€â”€ SQL/
â”‚   â”œâ”€â”€ create_.sql         â†’ Scripts de criaÃ§Ã£o de schemas, tabelas e views
â”‚   â””â”€â”€ popula_.sql         â†’ Scripts de populaÃ§Ã£o das dimensÃµes na camada gold
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 â†’ Arquivos CSV gerados pelo Python
â”‚   â””â”€â”€ (outros dados brutos)
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ preparacao_dados.py  â†’ Script Python para leitura e padronizaÃ§Ã£o
â”‚
â””â”€â”€ README.md                â† VocÃª estÃ¡ aqui!

